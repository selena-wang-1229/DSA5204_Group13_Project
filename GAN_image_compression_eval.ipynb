{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":39911,"sourceType":"datasetVersion","datasetId":31296},{"sourceId":684912,"sourceType":"datasetVersion","datasetId":347015},{"sourceId":8026414,"sourceType":"datasetVersion","datasetId":4730309},{"sourceId":8042130,"sourceType":"datasetVersion","datasetId":4741508},{"sourceId":8042217,"sourceType":"datasetVersion","datasetId":4741574}],"dockerImageVersionId":29507,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"08963816-b283-4302-af42-1357b7e25052","_uuid":"e265b52c-584d-4f80-92ab-f9bfec0f3734","execution":{"iopub.status.busy":"2024-04-06T11:25:26.272434Z","iopub.execute_input":"2024-04-06T11:25:26.272751Z","iopub.status.idle":"2024-04-06T11:25:26.500336Z","shell.execute_reply.started":"2024-04-06T11:25:26.272707Z","shell.execute_reply":"2024-04-06T11:25:26.49927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nimport torchvision.utils as vutils\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport copy\nimport time\nimport cv2 as cv\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.image as mpimg\n\nimport torchvision.transforms.functional as TF","metadata":{"_cell_guid":"c4ab2f4f-a173-4553-a22f-f35a2d1db962","_uuid":"04dc0a56-cb90-4c69-b973-0c79214dc59e","execution":{"iopub.status.busy":"2024-04-06T11:25:26.502088Z","iopub.execute_input":"2024-04-06T11:25:26.502381Z","iopub.status.idle":"2024-04-06T11:25:27.748908Z","shell.execute_reply.started":"2024-04-06T11:25:26.502332Z","shell.execute_reply":"2024-04-06T11:25:27.748028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dir = r'/kaggle/input/kodak-data-jpg/kodak_data_jpg//'\nimg_list = os.listdir(img_dir)\nprint(len(img_list))\nvalid_ratio = 0.8","metadata":{"_cell_guid":"15441219-cac0-409e-bbc6-a90c647c9665","_uuid":"72f80c88-1643-4205-8688-7916305d26f2","execution":{"iopub.status.busy":"2024-04-06T11:25:27.750226Z","iopub.execute_input":"2024-04-06T11:25:27.750457Z","iopub.status.idle":"2024-04-06T11:25:27.824873Z","shell.execute_reply.started":"2024-04-06T11:25:27.750419Z","shell.execute_reply":"2024-04-06T11:25:27.823931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvertToRGB: \n    def __call__(self, image): \n        if image.mode != 'RGB': \n            image = image.convert('RGB') \n        return image\n\n\nclass ImageData(Dataset):\n    def __init__(self,is_train=True):\n        self.is_train = is_train\n        self.transform = transforms.Compose([ConvertToRGB(),\n                                             transforms.Resize((218, 178)),\n                                             #transforms.Grayscale(num_output_channels=3),\n                                             transforms.ToTensor(),])\n        self.train_index = int(valid_ratio * len(img_list))\n        self.crop = transforms.CenterCrop((218,178))\n    def __len__(self):\n        if self.is_train:\n            return self.train_index\n        else:\n            return len(img_list) - self.train_index -1\n    def __getitem__(self, index):\n        if not self.is_train:\n            index = self.train_index + index\n#         print(\"hey  \"*4 + str(index))\n        img = mpimg.imread(img_dir+img_list[index])\n        img = self.crop(TF.to_pil_image(img))\n        img = self.transform(img)\n        img = (img-0.5) /0.5\n#         img = (img - 255.0) / 255.0\n        return img","metadata":{"_cell_guid":"352ebe3e-f5e0-4fce-b5da-71a230783edd","_uuid":"8cf61d41-c8f2-4a15-89cc-3be91e942e62","execution":{"iopub.status.busy":"2024-04-06T11:25:27.826263Z","iopub.execute_input":"2024-04-06T11:25:27.826588Z","iopub.status.idle":"2024-04-06T11:25:27.838803Z","shell.execute_reply.started":"2024-04-06T11:25:27.826532Z","shell.execute_reply":"2024-04-06T11:25:27.83794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=5\ndataset = ImageData(is_train=False)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\ndevice = 'cuda'","metadata":{"_cell_guid":"9732df15-3bc9-46ec-be0c-304661836ac2","_uuid":"dcdd031a-9938-40c6-a3cc-7417733e858d","execution":{"iopub.status.busy":"2024-04-06T11:25:27.842178Z","iopub.execute_input":"2024-04-06T11:25:27.842627Z","iopub.status.idle":"2024-04-06T11:25:27.851556Z","shell.execute_reply.started":"2024-04-06T11:25:27.842424Z","shell.execute_reply":"2024-04-06T11:25:27.850882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = next(iter(dataloader))\nprint(a[0].shape)\nimg = a[3]\nimg = img *0.5 + 0.5\nplt.imshow(img.permute(1,2,0))","metadata":{"_cell_guid":"8d126d61-eebd-4959-adc4-d0cbfda2278c","_uuid":"75e6a343-b614-481e-8a12-3eca4ff0c7b0","execution":{"iopub.status.busy":"2024-04-06T11:25:27.854579Z","iopub.execute_input":"2024-04-06T11:25:27.85488Z","iopub.status.idle":"2024-04-06T11:25:28.217745Z","shell.execute_reply.started":"2024-04-06T11:25:27.854827Z","shell.execute_reply":"2024-04-06T11:25:28.216871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"_cell_guid":"8e6a177b-dc74-401d-8ffa-5befd521651e","_uuid":"0511b538-0033-492e-a269-4b1b64d320ef","execution":{"iopub.status.busy":"2024-04-06T11:25:28.219067Z","iopub.execute_input":"2024-04-06T11:25:28.21937Z","iopub.status.idle":"2024-04-06T11:25:28.225671Z","shell.execute_reply.started":"2024-04-06T11:25:28.219319Z","shell.execute_reply":"2024-04-06T11:25:28.224647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 178\nIMG_HEIGHT = 218\nlatent_size = 200","metadata":{"_cell_guid":"a3e261cf-79be-4cf6-bfd4-208be76cbd12","_uuid":"b5953492-9a59-43bd-9a2e-5f69e5227946","execution":{"iopub.status.busy":"2024-04-06T11:25:28.226919Z","iopub.execute_input":"2024-04-06T11:25:28.227249Z","iopub.status.idle":"2024-04-06T11:25:28.235942Z","shell.execute_reply.started":"2024-04-06T11:25:28.227195Z","shell.execute_reply":"2024-04-06T11:25:28.235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_images_to_show = 24\n\n\nvalid_dataset = ImageData(is_train=False)\nbatch_size = num_images_to_show\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\nvalid_batch = next(iter(valid_dataloader)).to(device)\nvalid_batch_1 = next(iter(valid_dataloader)).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:28.237066Z","iopub.execute_input":"2024-04-06T11:25:28.237504Z","iopub.status.idle":"2024-04-06T11:25:32.085795Z","shell.execute_reply.started":"2024-04-06T11:25:28.237303Z","shell.execute_reply":"2024-04-06T11:25:32.085135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoder Model\nclass Encoder(nn.Module):\n    def __init__(self,num_channels_in_encoder):\n        super(Encoder, self).__init__()\n        \n        # ENCODER\n\n        # 64x64x64\n        self.e_conv_1 = nn.Sequential(\n            nn.ZeroPad2d((1, 2, 1, 2)),\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5, 5), stride=(2, 2)),nn.LeakyReLU()\n        )\n\n        # 128x32x32\n        self.e_conv_2 = nn.Sequential(\n            nn.ZeroPad2d((1, 2, 1, 2)),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(5, 5), stride=(2, 2)),\n            nn.LeakyReLU()\n        )\n        \n        # 128x32x32\n        self.e_block_1 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 128x32x32\n        self.e_block_2 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 128x32x32\n        self.e_block_3 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 32x32x32\n        self.e_conv_3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=num_channels_in_encoder, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n            nn.Tanh()\n        )\n    def forward(self, x):\n        ec1 = self.e_conv_1(x)\n        ec2 = self.e_conv_2(ec1)\n        eblock1 = self.e_block_1(ec2) + ec2\n        eblock2 = self.e_block_2(eblock1) + eblock1\n        eblock3 = self.e_block_3(eblock2) + eblock2\n        ec3 = self.e_conv_3(eblock3)  # in [-1, 1] from tanh activation\n        return ec3","metadata":{"_cell_guid":"0ef5c761-0d0f-490e-a4f8-b770c3eab3bd","_uuid":"5fd1ec79-1cc6-4b96-b451-f74d29969670","execution":{"iopub.status.busy":"2024-04-06T11:25:32.087344Z","iopub.execute_input":"2024-04-06T11:25:32.087672Z","iopub.status.idle":"2024-04-06T11:25:32.110045Z","shell.execute_reply.started":"2024-04-06T11:25:32.087612Z","shell.execute_reply":"2024-04-06T11:25:32.109039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"_cell_guid":"5bff9e09-cee6-428a-8368-95da81e9f10a","_uuid":"839c8341-9f75-4a31-8b7e-818269e482b5","execution":{"iopub.status.busy":"2024-04-06T11:25:32.111563Z","iopub.execute_input":"2024-04-06T11:25:32.111943Z","iopub.status.idle":"2024-04-06T11:25:32.122034Z","shell.execute_reply.started":"2024-04-06T11:25:32.111852Z","shell.execute_reply":"2024-04-06T11:25:32.121144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator / Decoder Model\n\nclass Generator(nn.Module):\n    def __init__(self,num_channels_in_encoder):\n        super(Generator, self).__init__()\n        \n        # DECODER\n#         self.latent_fc1 = nn.Sequential(\n#             nn.Linear(latent_size,1000),\n#             nn.Sigmoid(),\n#         )\n#         self.latent_fc2 = nn.Sequential(\n#             nn.Linear(1000,54*44),\n#             nn.Sigmoid(),\n#         )\n        # 128x64x64\n        self.d_up_conv_1 = nn.Sequential(\n        nn.Conv2d(in_channels=num_channels_in_encoder, out_channels=64, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=(2, 2), stride=(2, 2))\n        )\n\n        # 128x64x64\n        self.d_block_1 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 128x64x64\n        self.d_block_2 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 128x64x64\n        self.d_block_3 = nn.Sequential(\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n        )\n\n        # 256x128x128\n        self.d_up_conv_2 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ZeroPad2d((1, 1, 1, 1)),\n            nn.ConvTranspose2d(in_channels=32, out_channels=256, kernel_size=(2, 2), stride=(2, 2))\n        )\n\n        # 3x128x128\n        self.d_up_conv_3 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=16, kernel_size=(3, 3), stride=(1, 1)),\n            nn.LeakyReLU(),\n\n            nn.ReflectionPad2d((3, 3, 3, 3)),\n            nn.Conv2d(in_channels=16, out_channels=3, kernel_size=(3, 3), stride=(1, 1)),\n            nn.Tanh()\n        )\n\n        \n        \n    def forward(self, x):\n        uc1 = self.d_up_conv_1(x)\n        dblock1 = self.d_block_1(uc1) + uc1\n        dblock2 = self.d_block_2(dblock1) + dblock1\n        dblock3 = self.d_block_3(dblock2) + dblock2\n        uc2 = self.d_up_conv_2(dblock3)\n        dec = self.d_up_conv_3(uc2)\n        return dec","metadata":{"_cell_guid":"1c175dca-7190-4bb2-a510-1d86de4e902c","_uuid":"4ddb97c8-6514-4cab-817b-8222e972596e","execution":{"iopub.status.busy":"2024-04-06T11:25:32.123336Z","iopub.execute_input":"2024-04-06T11:25:32.123588Z","iopub.status.idle":"2024-04-06T11:25:32.149037Z","shell.execute_reply.started":"2024-04-06T11:25:32.123541Z","shell.execute_reply":"2024-04-06T11:25:32.148142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_channels_in_encoder = 18\nnetE28 = Encoder(num_channels_in_encoder).to(device)\nnetE28.apply(weights_init)\n\nnum_channels_in_encoder = 18\nnetG28 = Generator(num_channels_in_encoder).to(device)\nnetG28.apply(weights_init)\n\nnetG28.load_state_dict(torch.load(\"/kaggle/input/gan-model/netG18.model\"))\nnetE28.load_state_dict(torch.load(\"/kaggle/input/gan-model/netE18.model\"))\n\n\nnetE28.eval()\nnetG28.eval()\n\n\nreconstructed_img_28 = netG28(netE28(valid_batch))\nreconstructed_img_28_1 = netG28(netE28(valid_batch_1))\n\n\n\n\ndel netE28\ndel netG28\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:32.150338Z","iopub.execute_input":"2024-04-06T11:25:32.150694Z","iopub.status.idle":"2024-04-06T11:25:33.047973Z","shell.execute_reply.started":"2024-04-06T11:25:32.150577Z","shell.execute_reply":"2024-04-06T11:25:33.047098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_channels_in_encoder = 16\nnetG16 = Generator(num_channels_in_encoder).to(device)\nnetG16.apply(weights_init)\n\nnum_channels_in_encoder = 16\nnetE16 = Encoder(num_channels_in_encoder).to(device)\nnetE16.apply(weights_init)\n\nnetG16.load_state_dict(torch.load(\"/kaggle/input/trained-image-compressionmodels/netG16.model\"))\nnetE16.load_state_dict(torch.load(\"/kaggle/input/trained-image-compressionmodels/netE16.model\"))\n\n\nnetE16.eval()\nnetG16.eval()\nreconstructed_img_16 = netG16(netE16(valid_batch))\nreconstructed_img_16_1 = netG16(netE16(valid_batch_1))\n\ndel netE16\ndel netG16\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:33.049408Z","iopub.execute_input":"2024-04-06T11:25:33.049716Z","iopub.status.idle":"2024-04-06T11:25:33.454718Z","shell.execute_reply.started":"2024-04-06T11:25:33.049663Z","shell.execute_reply":"2024-04-06T11:25:33.453997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_channels_in_encoder = 8\nnetE8 = Encoder(num_channels_in_encoder).to(device)\nnetE8.apply(weights_init)\n\n\nnetG8 = Generator(num_channels_in_encoder).to(device)\nnetG8.apply(weights_init)\n\n\nnetG8.load_state_dict(torch.load(\"/kaggle/input/trained-image-compressionmodels/netG8.model\"))\nnetE8.load_state_dict(torch.load(\"/kaggle/input/trained-image-compressionmodels/netE8.model\"))\n\n\nnetG8.eval()\nnetE8.eval()\n\nreconstructed_img_8 = netG8(netE8(valid_batch))\nreconstructed_img_8_1 = netG8(netE8(valid_batch_1))\n\ndel netE8\ndel netG8\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:33.45583Z","iopub.execute_input":"2024-04-06T11:25:33.456075Z","iopub.status.idle":"2024-04-06T11:25:33.739962Z","shell.execute_reply.started":"2024-04-06T11:25:33.456018Z","shell.execute_reply":"2024-04-06T11:25:33.739152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nf, axarr = plt.subplots(4,4)\n\naxarr[0,0].title.set_text('Original \\n Image')\naxarr[0,1].title.set_text('Reconstructed Image with \\n 43% Compression')\naxarr[0,2].title.set_text('Reconstructed Image with \\n 68% Compression')\naxarr[0,3].title.set_text('Reconstructed Image with \\n 84% Compression')\n\nfor i in range(4):\n    axarr[0,i].title.set_fontsize(15)\n\nfor i in range(4):\n    axarr[i,0].imshow((valid_batch[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5)\n    axarr[i,1].imshow((reconstructed_img_28[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5)\n    axarr[i,2].imshow((reconstructed_img_16[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5)\n    axarr[i,3].imshow((reconstructed_img_8[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5)\n    f.set_figheight(20)\n    f.set_figwidth(20)\nplt.show()","metadata":{"_cell_guid":"8b16da2d-dd02-4cd7-a846-858e10b1d498","_uuid":"455c713c-47dc-49a1-b127-db82978fea5c","execution":{"iopub.status.busy":"2024-04-06T11:29:30.342045Z","iopub.execute_input":"2024-04-06T11:29:30.342362Z","iopub.status.idle":"2024-04-06T11:29:32.922205Z","shell.execute_reply.started":"2024-04-06T11:29:30.342316Z","shell.execute_reply":"2024-04-06T11:29:32.920846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig('results.png')\nf.savefig('results.png')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:29:37.140587Z","iopub.execute_input":"2024-04-06T11:29:37.140883Z","iopub.status.idle":"2024-04-06T11:29:37.817591Z","shell.execute_reply.started":"2024-04-06T11:29:37.140842Z","shell.execute_reply":"2024-04-06T11:29:37.816605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axarr = plt.subplots(2,2)\n\naxarr[0,0].title.set_text('Original \\n Image')\naxarr[0,1].title.set_text('Reconstructed Image with \\n 43% Compression')\naxarr[1,0].title.set_text('Reconstructed Image with \\n 68% Compression')\naxarr[1,1].title.set_text('Reconstructed Image with \\n 84% Compression')\n\nfor i in range(2):\n    for j in range(2):\n        axarr[i,j].title.set_fontsize(40)\ni = 0\n\n\nreimg = (valid_batch_1[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5\nreimg_28 = (reconstructed_img_28_1[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\nreimg_16 = (reconstructed_img_16_1[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\nreimg_8 = (reconstructed_img_8_1[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\n\n\n\naxarr[0,0].imshow(reimg)\naxarr[0,1].imshow(reimg_28)\naxarr[1,0].imshow(reimg_16)\naxarr[1,1].imshow(reimg_8)\nf.set_figheight(50)\nf.set_figwidth(50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:29:38.827537Z","iopub.execute_input":"2024-04-06T11:29:38.827844Z","iopub.status.idle":"2024-04-06T11:29:41.008765Z","shell.execute_reply.started":"2024-04-06T11:29:38.827789Z","shell.execute_reply":"2024-04-06T11:29:41.007755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig('results1.png')\nf.savefig('results1.png')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:43.704263Z","iopub.status.idle":"2024-04-06T11:25:43.704762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\nfrom math import exp\n\ndef gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n    return gauss/gauss.sum()\n\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\n\ndef _ssim(img1, img2, window, window_size, channel, size_average = True):\n    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n\n    mu1_sq = mu1.pow(2)\n    mu2_sq = mu2.pow(2)\n    mu1_mu2 = mu1*mu2\n\n    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n\n    C1 = 0.01**2\n    C2 = 0.03**2\n\n    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n\n    if size_average:\n        return ssim_map.mean()\n    else:\n        return ssim_map.mean(1).mean(1).mean(1)\n\nclass SSIM(torch.nn.Module):\n    def __init__(self, window_size = 11, size_average = True):\n        super(SSIM, self).__init__()\n        self.window_size = window_size\n        self.size_average = size_average\n        self.channel = 1\n        self.window = create_window(window_size, self.channel)\n\n    def forward(self, img1, img2):\n        (_, channel, _, _) = img1.size()\n\n        if channel == self.channel and self.window.data.type() == img1.data.type():\n            window = self.window\n        else:\n            window = create_window(self.window_size, channel)\n            \n            if img1.is_cuda:\n                window = window.cuda(img1.get_device())\n            window = window.type_as(img1)\n            \n            self.window = window\n            self.channel = channel\n\n\n        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n\ndef ssim(img1, img2, window_size = 11, size_average = True):\n    (_, channel, _, _) = img1.size()\n    window = create_window(window_size, channel)\n    \n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())\n    window = window.type_as(img1)\n    \n    return _ssim(img1, img2, window, window_size, channel, size_average)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:29:53.530319Z","iopub.execute_input":"2024-04-06T11:29:53.530613Z","iopub.status.idle":"2024-04-06T11:29:53.556058Z","shell.execute_reply.started":"2024-04-06T11:29:53.530571Z","shell.execute_reply":"2024-04-06T11:29:53.555201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reimg = reimg.view(1,reimg.shape[0],reimg.shape[1],reimg.shape[2])\nreimg_28 = reimg_28.view(1,reimg_28.shape[0],reimg_28.shape[1],reimg_28.shape[2])\nreimg_16 = reimg_16.view(1,reimg_16.shape[0],reimg_16.shape[1],reimg_16.shape[2])\nreimg_8 = reimg_8.view(1,reimg_8.shape[0],reimg_8.shape[1],reimg_8.shape[2])","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:29:57.993972Z","iopub.execute_input":"2024-04-06T11:29:57.994273Z","iopub.status.idle":"2024-04-06T11:29:58.001682Z","shell.execute_reply.started":"2024-04-06T11:29:57.994231Z","shell.execute_reply":"2024-04-06T11:29:58.000716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reimg = int(reimg.view(1,reimg.shape[0],reimg.shape[1],reimg.shape[2]) * 256)\n# reimg_28 = int(reimg_28.view(1,reimg_28.shape[0],reimg_28.shape[1],reimg_28.shape[2]) *256)\n# reimg_16 = int(reimg_16.view(1,reimg_16.shape[0],reimg_16.shape[1],reimg_16.shape[2]) *256)\n# reimg_8 = int(reimg_8.view(1,reimg_8.shape[0],reimg_8.shape[1],reimg_8.shape[2]) *256)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:25:43.70986Z","iopub.status.idle":"2024-04-06T11:25:43.710417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from torch.autograd import Variable\n\n# img1 = Variable(torch.rand(1, 1, 256, 256))\n# img2 = Variable(torch.rand(1, 1, 256, 256))\n\n# if torch.cuda.is_available():\n#     img1 = img1.cuda()\n#     img2 = img2.cuda()\n\n\n# reimg_28 = reimg_28.view(1,reimg_28.shape[0],reimg_28.shape[1],reimg_28.shape[2])\n# reimg = reimg.view(1,reimg.shape[0],reimg.shape[1],reimg.shape[2])\n# reimg = reimg.view(1,reimg.shape[0],reimg.shape[1],reimg.shape[2])\nprint(ssim(reimg, reimg_28))\nprint(ssim(reimg, reimg_16))\nprint(ssim(reimg, reimg_8))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:30:02.625298Z","iopub.execute_input":"2024-04-06T11:30:02.625593Z","iopub.status.idle":"2024-04-06T11:30:02.975075Z","shell.execute_reply.started":"2024-04-06T11:30:02.625551Z","shell.execute_reply":"2024-04-06T11:30:02.974362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reimg.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:30:07.662603Z","iopub.execute_input":"2024-04-06T11:30:07.663005Z","iopub.status.idle":"2024-04-06T11:30:07.669064Z","shell.execute_reply.started":"2024-04-06T11:30:07.662948Z","shell.execute_reply":"2024-04-06T11:30:07.668097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compressed_sizes","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:36:27.369407Z","iopub.execute_input":"2024-04-06T11:36:27.369735Z","iopub.status.idle":"2024-04-06T11:36:27.375381Z","shell.execute_reply.started":"2024-04-06T11:36:27.369688Z","shell.execute_reply":"2024-04-06T11:36:27.374506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_psnr(a, b):\n    mse = torch.mean((a - b)**2).item()\n    return -10 * math.log10(mse)\n\ndef compute_bitrate(compressed_size, original_size):\n    bit_rate = compressed_size * 8 / original_size # 乘以8将字节转换为比特\n    return bit_rate\n\n\n\nfor i in range(num_images_to_show):\n\n    original_images = (valid_batch[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5\n    compressed_images = (reconstructed_img_28[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\n    #compressed_sizes = compressed_images.size()\n    \n    original_images = original_images.view(\n        1,\n        original_images.shape[0],\n        original_images.shape[1],\n        original_images.shape[2])\n    compressed_images = compressed_images.view(\n        1,\n        compressed_images.shape[0],\n        compressed_images.shape[1],\n        compressed_images.shape[2])\n    \n\n    #original_images = original_images.to(device)\n    #compressed_images = compressed_images.to(device)\n    \n\n    # 计算PSNR和SSIM\n    psnr = compute_psnr(original_images, compressed_images)\n    ms_ssim = -10 * math.log10(1-ssim(original_images, compressed_images))\n\n    \n    # 计算Bit-rate，这需要你知道压缩后的图像大小\n    # 下面的示例假设`compressed_sizes`是一个包含每张图片压缩后大小的tensor\n    original_size = original_images.nelement() * original_images.element_size()  # 总字节数\n    compressed_sizes = compressed_images.nelement() * compressed_images.element_size()\n    bit_rate = compute_bitrate(compressed_sizes, original_size)\n    \n    # 输出结果\n    print(f'PSNR: {psnr:.2f}dB')\n    print(f'MS-SSIM: {ms_ssim:.4f}dB')\n    print(f'Bit-rate: {bit_rate:.3f}bpp')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:27:41.396017Z","iopub.execute_input":"2024-04-06T12:27:41.396359Z","iopub.status.idle":"2024-04-06T12:27:41.77687Z","shell.execute_reply.started":"2024-04-06T12:27:41.39631Z","shell.execute_reply":"2024-04-06T12:27:41.775871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\ndef compute_psnr(a, b):\n    mse = torch.mean((a - b)**2).item()\n    return -10 * math.log10(mse)\n\n\ndef compute_msssim(a, b):\n    return -10 * math.log10(1-ssim(a, b).item())\n\ndef compute_bpp(a, b):\n    size = b.size()\n    num_pixels = size[0] * size[2] * size[3]\n    return sum(torch.log(likelihoods).sum() / (-math.log(2) * num_pixels)\n              for likelihoods in a.values()).item()\n\n\nfor i in range(num_images_to_show):\n\n    original_images = (valid_batch[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5\n    compressed_images = (reconstructed_img_28[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\n    #compressed_sizes = compressed_images.size()\n    \n    \n    original_images = original_images.view(\n        1,\n        original_images.shape[0],\n        original_images.shape[1],\n        original_images.shape[2])\n    compressed_images = compressed_images.view(\n        1,\n        compressed_images.shape[0],\n        compressed_images.shape[1],\n        compressed_images.shape[2])\n    \n\n    #original_images = original_images.to(device)\n    #compressed_images = compressed_images.to(device)\n    \n\n    # 计算PSNR和SSIM\n    psnr = compute_psnr(original_images, compressed_images)\n    ms_ssim = compute_msssim(original_images, compressed_images)\n    \n    # 计算Bit-rate，这需要你知道压缩后的图像大小\n    # 下面的示例假设`compressed_sizes`是一个包含每张图片压缩后大小的tensor\n    original_size = original_images.nelement() * original_images.element_size()  # 总字节数\n    compressed_sizes = compressed_images.nelement() * compressed_images.element_size()\n    bit_rate = compute_bpp(original_images, compressed_images)\n    \n    # 输出结果\n    print(f'PSNR: {psnr:.2f}dB')\n    print(f'MS-SSIM: {ms_ssim:.4f}')\n    print(f'Bit-rate: {bit_rate:.3f}bpp')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:16:07.168141Z","iopub.execute_input":"2024-04-06T12:16:07.168483Z","iopub.status.idle":"2024-04-06T12:16:07.303002Z","shell.execute_reply.started":"2024-04-06T12:16:07.168425Z","shell.execute_reply":"2024-04-06T12:16:07.301913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_bpp(out_net):\n    size = out_net['x_hat'].size()\n    num_pixels = size[0] * size[2] * size[3]\n    return sum(torch.log(likelihoods).sum() / (-math.log(2) * num_pixels)\n              for likelihoods in out_net['likelihoods'].values()).item()\n\ni=1\noriginal_images = (valid_batch[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5\ncompressed_images = (reconstructed_img_28[i].cpu().detach().permute(1, 2, 0) *0.5) + 0.5\noriginal_images = original_images.view(\n    1,\n    original_images.shape[0],\n    original_images.shape[1],\n    original_images.shape[2])\ncompressed_images = compressed_images.view(\n    1,\n    compressed_images.shape[0],\n    compressed_images.shape[1],\n    compressed_images.shape[2])","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:44:05.838334Z","iopub.execute_input":"2024-04-06T12:44:05.838637Z","iopub.status.idle":"2024-04-06T12:44:05.850029Z","shell.execute_reply.started":"2024-04-06T12:44:05.838594Z","shell.execute_reply":"2024-04-06T12:44:05.849037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = compressed_images.size()\nnum_pixels = size[0] * size[2] * size[3]\nnum_pixels","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:45:00.44897Z","iopub.execute_input":"2024-04-06T12:45:00.449306Z","iopub.status.idle":"2024-04-06T12:45:00.455518Z","shell.execute_reply.started":"2024-04-06T12:45:00.449255Z","shell.execute_reply":"2024-04-06T12:45:00.454658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((valid_batch[i].cpu().detach().permute(1, 2, 0) * 0.5) + 0.5).values()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:46:41.578426Z","iopub.execute_input":"2024-04-06T12:46:41.578719Z","iopub.status.idle":"2024-04-06T12:46:41.595466Z","shell.execute_reply.started":"2024-04-06T12:46:41.578677Z","shell.execute_reply":"2024-04-06T12:46:41.59436Z"},"trusted":true},"execution_count":null,"outputs":[]}]}